{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "1889bd2e_8ea43096",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 21
      },
      "lineNbr": 0,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-01T13:16:42Z",
      "side": 1,
      "message": "Thank You for working on this! I\u0027m having one minor issue related with current code. However, even with this resolved, the new mechanism doesn\u0027t seem to work as intended, as immediately after deferring the read, websocket object gets destroyed, which leads to bmcweb crash. \nI\u0027m figuring out what could be the cause of that, maybe it\u0027s something trivial that we both had missed.",
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "d32a40c0_e783a99c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 21
      },
      "lineNbr": 0,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-02T11:11:11Z",
      "side": 1,
      "message": "Adding a couple comments after some debugging. Ed, please take a look and let me know what are Your thoughts on this.",
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "429c139f_697c9052",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 21
      },
      "lineNbr": 0,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-02T16:47:28Z",
      "side": 1,
      "message": "Another set of issues that I came across during debugging. I think that after addressing them, along with the remaining ones, we might finally get it working as intended.",
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "3c3c48ff_aa395649",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 21
      },
      "lineNbr": 0,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-02T20:44:25Z",
      "side": 1,
      "message": "Yep, this makes sense.  I think I know the fix, which is a member variable shared_ptr pointing to itself that gets filled when the reading has been defered.  I can try to make the changes.",
      "parentUuid": "1889bd2e_8ea43096",
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "51c97b0e_2b6869b6",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 21
      },
      "lineNbr": 0,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-06T14:53:30Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "3c3c48ff_aa395649",
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "88691d2c_42a20603",
        "filename": "http/websocket.hpp",
        "patchSetId": 21
      },
      "lineNbr": 228,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-02T11:11:11Z",
      "side": 1,
      "message": "In the current state, Websocket object gets destroyed right after leaving doRead() function (reading is being deferred). We\u0027d need to think of a way to prolong its lifespan. One thing that came to my mind is to pass shared_from_this into openHandler. That would require some refactoring though, besides I do not know if that would be safe at all.",
      "range": {
        "startLine": 224,
        "startChar": 8,
        "endLine": 228,
        "endChar": 17
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "df0142db_1581dfad",
        "filename": "http/websocket.hpp",
        "patchSetId": 21
      },
      "lineNbr": 228,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-06T14:53:30Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "88691d2c_42a20603",
      "range": {
        "startLine": 224,
        "startChar": 8,
        "endLine": 228,
        "endChar": 17
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4324908a_97435720",
        "filename": "http/websocket.hpp",
        "patchSetId": 21
      },
      "lineNbr": 233,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-01T13:16:42Z",
      "side": 1,
      "message": "I\u0027m assuming that here readingDefered is supposed to be set to \u0027true\u0027?",
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "aa996b44_ece38107",
        "filename": "http/websocket.hpp",
        "patchSetId": 21
      },
      "lineNbr": 233,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-02T20:43:43Z",
      "side": 1,
      "message": "Yes, this should be true.",
      "parentUuid": "4324908a_97435720",
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "155952e7_5a850bb9",
        "filename": "http/websocket.hpp",
        "patchSetId": 21
      },
      "lineNbr": 233,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-06T14:53:30Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "aa996b44_ece38107",
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "77af170c_7d421b2e",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 120,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-02T11:11:11Z",
      "side": 1,
      "message": "I think this also would need to be synchronized with the acceptor handler. In a case where D-Bus handler finishes earlier, socket will not be created yet, which will cause doRead to crash.",
      "range": {
        "startLine": 117,
        "startChar": 12,
        "endLine": 120,
        "endChar": 27
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0bf06a23_13025f38",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 166,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-02T16:47:28Z",
      "side": 1,
      "message": "Consume ux2WsBuf before the next read.",
      "range": {
        "startLine": 166,
        "startChar": 19,
        "endLine": 166,
        "endChar": 36
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "77e61045_c92ba820",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 166,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-02T20:43:43Z",
      "side": 1,
      "message": "ACK.",
      "parentUuid": "0bf06a23_13025f38",
      "range": {
        "startLine": 166,
        "startChar": 19,
        "endLine": 166,
        "endChar": 36
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b7b53365_4767a126",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 166,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-06T16:22:33Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "77e61045_c92ba820",
      "range": {
        "startLine": 166,
        "startChar": 19,
        "endLine": 166,
        "endChar": 36
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "fda858d7_772cd2aa",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 230,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-02T16:47:28Z",
      "side": 1,
      "message": "Buffer sizes are inconsistent with \u0027nbdBufferSize\u0027 constant. Either increase their sizes, or decrease the constexpr. Otherwise we might get buffer overflow exceptions when calling buffers\u0027 prepare method.",
      "range": {
        "startLine": 226,
        "startChar": 4,
        "endLine": 230,
        "endChar": 52
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1da76e7b_c0452806",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 230,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-02T20:43:43Z",
      "side": 1,
      "message": "ACK.  The thinking is that the bmcweb buffers themselves should always be small, and we should rely on backpressure on the socket.",
      "parentUuid": "fda858d7_772cd2aa",
      "range": {
        "startLine": 226,
        "startChar": 4,
        "endLine": 230,
        "endChar": 52
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "eac18a27_c51ebbae",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 230,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-03T09:15:03Z",
      "side": 1,
      "message": "Unfortunately this idea doesn\u0027t seem to work. With this size (decreased constexpr to 8192) I get a buffer overflow exception in situation when incoming data is greater than buffer\u0027s size:\n\nMar 03 08:43:46 intel-obmc bmcweb[412]: (2023-03-03 08:43:46) [DEBUG \"nbd_proxy.hpp\":404] nbd-proxy.onMessage(len \u003d 16400)\nMar 03 08:43:46 intel-obmc bmcweb[412]: (2023-03-03 08:43:46) [CRITICAL \"webserver_main.cpp\":166] Threw exception to main: buffer overflow\n\nAfter increasing buffer sizes to the constexpr value (131088) the problem disappears.",
      "parentUuid": "1da76e7b_c0452806",
      "range": {
        "startLine": 226,
        "startChar": 4,
        "endLine": 230,
        "endChar": 52
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b9ab52a1_5a82c4db",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 230,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-03T18:16:01Z",
      "side": 1,
      "message": "\u003e Unfortunately this idea doesn\u0027t seem to work. With this size (decreased constexpr to 8192) I get a buffer overflow exception in situation when incoming data is greater than buffer\u0027s size:\n\n\nInteresting that nbd is sending individual websocket messages that are larger than 8K.  Something to improve in the future I guess.  I\u0027ve updated the size back to the 13M.\n\nI think the long term fix is to change to using async_read_SOME instead of async_read, so we can buffer\n\nhttps://www.boost.org/doc/libs/1_81_0/libs/beast/doc/html/beast/ref/boost__beast__websocket__stream/async_read_some.html\n\nBut that\u0027s a problem for another patch.\n\n\u003e \n\u003e Mar 03 08:43:46 intel-obmc bmcweb[412]: (2023-03-03 08:43:46) [DEBUG \"nbd_proxy.hpp\":404] nbd-proxy.onMessage(len \u003d 16400)\n\u003e Mar 03 08:43:46 intel-obmc bmcweb[412]: (2023-03-03 08:43:46) [CRITICAL \"webserver_main.cpp\":166] Threw exception to main: buffer overflow\n\u003e \n\u003e After increasing buffer sizes to the constexpr value (131088) the problem disappears.\n\nDone.",
      "parentUuid": "eac18a27_c51ebbae",
      "range": {
        "startLine": 226,
        "startChar": 4,
        "endLine": 230,
        "endChar": 52
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7b5d1962_20403840",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 344,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-02-28T02:55:04Z",
      "side": 1,
      "message": "Michal, please take a look and let me know if this solves the buffering problem.  Basically, this method allows avoiding reading the socket until a time at which it can be buffered, so we avoid the crash.  This seems better than an arbitrary delay, which might cause problems if we have buffering issues.",
      "range": {
        "startLine": 344,
        "startChar": 9,
        "endLine": 344,
        "endChar": 18
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "854e739c_397d3b3c",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 344,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-06T14:53:30Z",
      "side": 1,
      "message": "Confirmed that the solution works at its fundation.",
      "parentUuid": "7b5d1962_20403840",
      "range": {
        "startLine": 344,
        "startChar": 9,
        "endLine": 344,
        "endChar": 18
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8fe564e3_395c9685",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 374,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-02T11:45:14Z",
      "side": 1,
      "message": "Case similar to the one from NbdProxyServer::run; when peerSocket is not yet ready, this will fail (due to calling peerSocket.async_write_some).",
      "range": {
        "startLine": 374,
        "startChar": 4,
        "endLine": 374,
        "endChar": 57
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "79d96ee2_36584530",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 374,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-06T16:22:33Z",
      "side": 1,
      "message": "But now with deferRead(), onMessage can\u0027t be called before the peersocket is enabled, right?  Or maybe I\u0027m missing something, but I think the flow is:\n\nonOpen called\nconnection::deferRead() called\npeerSocket connects, and sets up (during this time onMessage can\u0027t be called)\nconnection::resumeRead() called\nonMessage called.\n\nMaybe I\u0027m missing what the problem is?",
      "parentUuid": "8fe564e3_395c9685",
      "range": {
        "startLine": 374,
        "startChar": 4,
        "endLine": 374,
        "endChar": 57
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b39c71ea_92fafcae",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 374,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-06T16:38:27Z",
      "side": 1,
      "message": "Actually the flow is a little bit different now. Connection::resumeRead() is called after D-Bus method call is handled. The thing is that at this moment peerSocket might not yet be connected, as it is done by acceptor.async_accept(), which might not have finished by that time (in my case that happened always). The result is that peerSocket is not yet connected, when we\u0027re resuming reading, and once we call either async_read_some or async_write_some, we get an exception.\n\nWe\u0027d need to delay connection::resumeRead() until both acceptor.async_accept() and systemBus-\u003easync_method_call() finish their job in order to fix that problem.",
      "parentUuid": "79d96ee2_36584530",
      "range": {
        "startLine": 374,
        "startChar": 4,
        "endLine": 374,
        "endChar": 57
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "da9035f7_4ec06e60",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 374,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-06T16:53:15Z",
      "side": 1,
      "message": "\u003e Actually the flow is a little bit different now. Connection::resumeRead() is called after D-Bus method call is handled. The thing is that at this moment peerSocket might not yet be connected, as it is done by acceptor.async_accept(), which might not have finished by that time (in my case that happened always). The result is that peerSocket is not yet connected, when we\u0027re resuming reading, and once we call either async_read_some or async_write_some, we get an exception.\n\u003e \n\u003e We\u0027d need to delay connection::resumeRead() until both acceptor.async_accept() and systemBus-\u003easync_method_call() finish their job in order to fix that problem.\n\nIn theory, it just needs to go in the async_accept call, right?  That won\u0027t complete until after the dbus call is made?  I think I just put the resume in the wrong spot.  Take a look at what I have now.",
      "parentUuid": "b39c71ea_92fafcae",
      "range": {
        "startLine": 374,
        "startChar": 4,
        "endLine": 374,
        "endChar": 57
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4f773488_59c31a58",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 374,
      "author": {
        "id": 1001329
      },
      "writtenOn": "2023-03-07T09:30:31Z",
      "side": 1,
      "message": "Unfortunately that doesn\u0027t fix the issue. NbdProxyServer::doRead() calls peerSocket.async_read_some(), and it will fail with \"Bad file descriptor\" if socket is not yet ready. The easiest fix would be to move doRead into async_accept, assuming that it\u0027s going to finish later than D-Bus method call (as it was in my case). However, in order to be 100% failproof, Connection::resumeRead() and NbdProxyServer::doRead() should be called after BOTH of these handlers finish.",
      "parentUuid": "da9035f7_4ec06e60",
      "range": {
        "startLine": 374,
        "startChar": 4,
        "endLine": 374,
        "endChar": 57
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5fd03b1f_8ba3db06",
        "filename": "include/nbd_proxy.hpp",
        "patchSetId": 21
      },
      "lineNbr": 374,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-08T00:35:40Z",
      "side": 1,
      "message": "I did the first one.",
      "parentUuid": "4f773488_59c31a58",
      "range": {
        "startLine": 374,
        "startChar": 4,
        "endLine": 374,
        "endChar": 57
      },
      "revId": "1c90594849a9b3626db6308680dad48b1cb69df1",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    }
  ]
}