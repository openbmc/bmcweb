{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "367fb162_4a1808d1",
        "filename": "redfish-core/lib/log_services.hpp",
        "patchSetId": 14
      },
      "lineNbr": 750,
      "author": {
        "id": 1000350
      },
      "writtenOn": "2023-12-13T02:40:34Z",
      "side": 0,
      "message": "need similar max size check?",
      "revId": "0e373b53f81fc1720050571755ecfcdc6dd9ba9b",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1983130a_64880fb0",
        "filename": "redfish-core/lib/log_services.hpp",
        "patchSetId": 14
      },
      "lineNbr": 750,
      "author": {
        "id": 1001762
      },
      "writtenOn": "2023-12-13T13:35:25Z",
      "side": 0,
      "message": "nope. In the file body case, the max chunk is defined to be 4k. So there is no chance of using higher memory. And we have a timeout in place for aborting large file offloads.",
      "parentUuid": "367fb162_4a1808d1",
      "revId": "0e373b53f81fc1720050571755ecfcdc6dd9ba9b",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9cd6be5b_e3c4c71b",
        "filename": "redfish-core/lib/log_services.hpp",
        "patchSetId": 14
      },
      "lineNbr": 750,
      "author": {
        "id": 1000350
      },
      "writtenOn": "2023-12-13T13:51:16Z",
      "side": 0,
      "message": "what\u0027s the error returned while aborting large dump offloads?\nwhat\u0027s the max dump size offloaded in your testing?\nI was thinking if we can avoid hitting this timeout by keeping nominal max dump size that can be offloaded with in this timeout.",
      "parentUuid": "1983130a_64880fb0",
      "revId": "0e373b53f81fc1720050571755ecfcdc6dd9ba9b",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5f985515_a5d8bdf1",
        "filename": "redfish-core/lib/log_services.hpp",
        "patchSetId": 14
      },
      "lineNbr": 750,
      "author": {
        "id": 1001762
      },
      "writtenOn": "2023-12-13T14:59:33Z",
      "side": 0,
      "message": "we cannot do that. The maximum size will be subjective. It depends on the network speed. We may be able to offload a 100MB file in the test setup but that does not mean that it will work in production environment. The clients will get same connection terminated error as they get for other timouts.",
      "parentUuid": "9cd6be5b_e3c4c71b",
      "revId": "0e373b53f81fc1720050571755ecfcdc6dd9ba9b",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7f195c2d_24677ffc",
        "filename": "redfish-core/lib/log_services.hpp",
        "patchSetId": 14
      },
      "lineNbr": 750,
      "author": {
        "id": 1000350
      },
      "writtenOn": "2023-12-13T15:05:38Z",
      "side": 0,
      "message": "agreed, in case of slow network even 5MB dump may not able to offload.\nwhat\u0027s the error returned while aborting dump offloads when timeout hit?",
      "parentUuid": "5f985515_a5d8bdf1",
      "revId": "0e373b53f81fc1720050571755ecfcdc6dd9ba9b",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "3bc5fa72_817465bb",
        "filename": "redfish-core/lib/log_services.hpp",
        "patchSetId": 14
      },
      "lineNbr": 750,
      "author": {
        "id": 1001762
      },
      "writtenOn": "2024-01-09T07:22:36Z",
      "side": 0,
      "message": "Done, put back size check",
      "parentUuid": "7f195c2d_24677ffc",
      "revId": "0e373b53f81fc1720050571755ecfcdc6dd9ba9b",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    }
  ]
}