{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "13c001f0_2167245f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2022-05-06T23:24:23Z",
      "side": 1,
      "message": "I\u0027m reading through this, and there\u0027s a pretty significant change being made to the memory usage here in that now we\u0027ll have AsyncMultiRequest objects for every node of every level of the tree that we\u0027re parsing, instead of just a single one at the top that manages all the outstanding requests.  That\u0027s a bit of a concern if we every want to dump the whole tree.  6 levels deep * number of leaf nodes is a bit big to be having an AsyncMultiRequest object for every level.  Maybe I\u0027m wrong though.\n\nThe other concern is that we\u0027re constructing a query param string, just to immediately decode it, which the old code didn\u0027t do, given it operated on the Query objects directly.  That seems less efficient than what exists.  Did you look into seeing if the Query object could be used as is, instead of generating intermediate strings?",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "069fe699_735e9a90",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000682
      },
      "writtenOn": "2022-05-09T16:57:40Z",
      "side": 1,
      "message": "\u003e 6 levels deep * number of leaf nodes is a bit big to be having an AsyncMultiRequest object for every level.  Maybe I\u0027m wrong though.\n\nThanks for the comment. That\u0027s a valid concern, but it\u0027s not very obvious to me whether this change introduces more memory usage. The existing algorithm captures a copy of the whole Query object, which as eliminated in this commit. This commits does create more AsyncMultiRequest objects but Given that AsyncMultiRequest only keeps two pointers as data members, it shouldn\u0027t be a big deal. Just for my knowledge, any other reasons why you are worried about it in the first place?\n\nI did a benchmark on real hardware.\n\n```\n  PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND\n 5887  2856 root     S     104m  10%   1   9% /tmp/bmcweb_after\n 5953  2856 root     S     104m  10%   0   9% /tmp/bmcweb_ori\nwget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d2)\u0027\n \n \n 5825  2856 root     S     108m  11%   1  29% /tmp/bmcweb_after\n 5955  2856 root     S     108m  11%   1  34% /tmp/bmcweb_ori\nwget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d3)\u0027\n \n \n21747  2856 root     R     138m  14%   1  27% /tmp/bmcweb_after\n16519  2856 root     S     138m  14%   1  25% /tmp/bmcweb_ori\nwget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d4)\u0027\n \n 2665  2856 root     S     178m  18%   0  19% /tmp/bmcweb_after\n29729  2856 root     S     181m  18%   1  20% /tmp/bmcweb_ori\nwget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d5)\u0027\n \n 8044  2856 root     S     237m  23%   1  14% /tmp/bmcweb_after\n13301  2856 root     R     227m  23%   0  28% /tmp/bmcweb_ori\nwget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d6)\u0027\n```\nI didn\u0027t see big difference on memory consumption between the two algorithms.\n\n\n\u003e The other concern is that we\u0027re constructing a query param string, just to immediately decode it, which the old code didn\u0027t do, given it operated on the Query objects directly.  That seems less efficient than what exists.  Did you look into seeing if the Query object could be used as is, instead of generating intermediate strings?\n\nThis is also a valid concern. I thought about this when implementing the algorithm. One thought at that time is to keep values of expand string and select string in |Query|. And we use vector of string_view to store selected attributes. Does this help solve your concern?\n\nPlease resolve if the above looks good.",
      "parentUuid": "13c001f0_2167245f",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4f9ccc56_724012bb",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2022-05-09T17:04:23Z",
      "side": 1,
      "message": "\u003e \u003e 6 levels deep * number of leaf nodes is a bit big to be having an AsyncMultiRequest object for every level.  Maybe I\u0027m wrong though.\n\u003e \n\u003e Thanks for the comment. That\u0027s a valid concern, but it\u0027s not very obvious to me whether this change introduces more memory usage. The existing algorithm captures a copy of the whole Query object, which as eliminated in this commit.\n\nBut it captures it once, not N times.\n\n\u003e This commits does create more AsyncMultiRequest objects but Given that AsyncMultiRequest only keeps two pointers as data members, it shouldn\u0027t be a big deal.\n\nGiven that that the handler also has captures, it\u0027s larger than just two pointers.\n\n\u003e Just for my knowledge, any other reasons why you are worried about it in the first place?\n\nBecause if I call $expand($levels\u003d6) on service root, it will limit the size of the response that can be given.\n\n\u003e \n\u003e I did a benchmark on real hardware.\n\u003e \n\u003e ```\n\u003e   PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND\n\u003e  5887  2856 root     S     104m  10%   1   9% /tmp/bmcweb_after\n\u003e  5953  2856 root     S     104m  10%   0   9% /tmp/bmcweb_ori\n\u003e wget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d2)\u0027\n\u003e  \n\u003e  \n\u003e  5825  2856 root     S     108m  11%   1  29% /tmp/bmcweb_after\n\u003e  5955  2856 root     S     108m  11%   1  34% /tmp/bmcweb_ori\n\u003e wget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d3)\u0027\n\u003e  \n\u003e  \n\u003e 21747  2856 root     R     138m  14%   1  27% /tmp/bmcweb_after\n\u003e 16519  2856 root     S     138m  14%   1  25% /tmp/bmcweb_ori\n\u003e wget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d4)\u0027\n\u003e  \n\u003e  2665  2856 root     S     178m  18%   0  19% /tmp/bmcweb_after\n\u003e 29729  2856 root     S     181m  18%   1  20% /tmp/bmcweb_ori\n\u003e wget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d5)\u0027\n\u003e  \n\u003e  8044  2856 root     S     237m  23%   1  14% /tmp/bmcweb_after\n\u003e 13301  2856 root     R     227m  23%   0  28% /tmp/bmcweb_ori\n\u003e wget -qO- \u0027http://localhost:18080/redfish/v1?$expand\u003d*($levels\u003d6)\u0027\n\u003e ```\n\u003e I didn\u0027t see big difference on memory consumption between the two algorithms.\n\nHow are you measuring memory usage with a single wget command?  Generally if you want to measure memory usage, you would run it in a loop from multiple threads, and see where you run out of resources.\n\n\u003e \n\u003e \n\u003e \u003e The other concern is that we\u0027re constructing a query param string, just to immediately decode it, which the old code didn\u0027t do, given it operated on the Query objects directly.  That seems less efficient than what exists.  Did you look into seeing if the Query object could be used as is, instead of generating intermediate strings?\n\u003e \n\u003e This is also a valid concern. I thought about this when implementing the algorithm. One thought at that time is to keep values of expand string and select string in |Query|. And we use vector of string_view to store selected attributes. Does this help solve your concern?\n\nI don\u0027t understand your proposed solution.  Can you either post a quick patch/snippet of what you\u0027re thinking?  In Query, there is no \"expand string\" it\u0027s only a structure with enum/int members, so I\u0027m a little confused.\n\n\u003e \n\u003e Please resolve if the above looks good.",
      "parentUuid": "069fe699_735e9a90",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "51f85883_ce34d62a",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000682
      },
      "writtenOn": "2022-05-09T18:39:55Z",
      "side": 1,
      "message": "\u003e How are you measuring memory usage with a single wget command?  Generally if you want to measure memory usage, you would run it in a loop from multiple threads, and see where you run out of resources.\n\nWe are comparing whether this commit increases memory usage, right? From the benchmark of a single thread, we know it does make much difference. Do you expect parallel requests change it so this commits consumes more memory?\n\nRegarding whether $expand\u003d*($levels\u003d6) will cause out of memory errors. That\u0027s not what this commit tries to solve, right? But if you need a benchmark, I can do that.\n\n\u003e I don\u0027t understand your proposed solution.  Can you either post a quick patch/snippet of what you\u0027re thinking?  In Query, there is no \"expand string\" it\u0027s only a structure with enum/int members, so I\u0027m a little confused.\n\nSomething like this.\n\n```\n// The struct stores the parsed query parameters of the default Redfish route.\nstruct Query\n{\n    // Only\n    bool isOnly \u003d false;\n    // Expand\n    uint8_t expandLevel \u003d 0;\n    ExpandType expandType \u003d ExpandType::None;\n    std::string expandStr;    \n\n    std::string selectedPropertiesStr;\n    std::vector\u003cstd::string_view\u003e selectedProperties;\n}\n```\n\nPeople might argue that it introduces duplicate information. I don\u0027t know if there\u0027s other ways if we want to include query parameters into the queries that we created in |AsyncMultiRequest|.\n\nOr, any other ideas how to make $level\u003d2 expand query invoke efficient $level\u003d1 expand query, other than what this commit proposes?",
      "parentUuid": "4f9ccc56_724012bb",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "074071ce_86690a10",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000682
      },
      "writtenOn": "2022-05-09T18:40:33Z",
      "side": 1,
      "message": "* From the benchmark of a single thread, we know it does \"not\" make much difference. \n\nMissed a not.",
      "parentUuid": "51f85883_ce34d62a",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7fca5522_d7b1f0a7",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2022-05-09T20:33:06Z",
      "side": 1,
      "message": "Keep in mind, you\u0027re benchmarking on a system that has 10-100X the memory bandwidth of other BMCs.  Your results might not be indicative of other bmcs, and your time is largely dominated by network, which isn\u0027t always the case.\n\n\n\u003e Do you expect parallel requests change it so this commits consumes more memory?\n\nYes, because of the way you\u0027re measuring, you\u0027re measuring at a point in time, and it\u0027s unlikely you caught the peak memory usage with your call, that\u0027s generally why we run multiple in parallel, so we\u0027re guaranteed to measure the \"peak\" usage, which per the developing guide, is what we optimize for, because if we run the bmc out of memory, it\u0027s a bad thing.\n\n\n\u003e Something like this.\n\nI\u0027m not really following how that would work.  If you already have epandLevel and expandType, what does expandStr give you?\n\n\n\u003e Or, any other ideas how to make $level\u003d2 expand query invoke efficient $level\u003d1 expand query, other than what this commit proposes?\n\nKeeping the existing \"parse the parameters once\" approach, then just make sure the delegate call can properly select sublevel handling instead of passing onto the existing handlers.",
      "parentUuid": "074071ce_86690a10",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "96b46627_6ab3f25a",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000682
      },
      "writtenOn": "2022-05-09T21:48:39Z",
      "side": 1,
      "message": "\u003e Your results might not be indicative of other bmcs, and your time is largely dominated by network, which isn\u0027t always the case. \nWhy is it dominated by network? \n\n\u003e Yes, because of the way you\u0027re measuring, you\u0027re measuring at a point in time, and it\u0027s unlikely you caught the peak memory usage with your call, that\u0027s generally why we run multiple in parallel, so we\u0027re guaranteed to measure the \"peak\" usage, which per the developing guide, is what we optimize for, because if we run the bmc out of memory, it\u0027s a bad thing.\nI am capturing the memory usage continuously (in a certain interval) and chose the \"peak\" usage.\n\nI did another benchmark where 4 threads are requesting data in parallel. Peak Mem usage is mapped out below. \n\n```\n25878  2856 root     R     194m  20%   1  38% /tmp/bmcweb_after       \n19005  2856 root     R     215m  22%   1  36% /tmp/bmcweb_ori           \n```\n\n\u003e I\u0027m not really following how that would work.  If you already have epandLevel and expandType, what does expandStr give you?\n\nYou don\u0027t want to re-generate the string again, so I propose to store the original value of those query parameters if we are going to use them again. But true, for expand, the value has to change. For select, we can probably directly use the original string. \n\n\u003e Keeping the existing \"parse the parameters once\" approach, then just make sure the delegate call can properly select sublevel handling instead of passing onto the existing handlers.\nHow do we \"make sure the delegate call can properly select sublevel handling\"",
      "parentUuid": "7fca5522_d7b1f0a7",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e37cf22b_455f598f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2022-05-10T16:41:59Z",
      "side": 1,
      "message": "\u003e \u003e Your results might not be indicative of other bmcs, and your time is largely dominated by network, which isn\u0027t always the case. \n\u003e Why is it dominated by network? \n\nBecause you have a much faster bmc processor.\n\n\u003e \n\u003e \u003e Yes, because of the way you\u0027re measuring, you\u0027re measuring at a point in time, and it\u0027s unlikely you caught the peak memory usage with your call, that\u0027s generally why we run multiple in parallel, so we\u0027re guaranteed to measure the \"peak\" usage, which per the developing guide, is what we optimize for, because if we run the bmc out of memory, it\u0027s a bad thing.\n\u003e I am capturing the memory usage continuously (in a certain interval) and chose the \"peak\" usage.\n\u003e \n\u003e I did another benchmark where 4 threads are requesting data in parallel. Peak Mem usage is mapped out below. \n\u003e \n\u003e ```\n\u003e 25878  2856 root     R     194m  20%   1  38% /tmp/bmcweb_after       \n\u003e 19005  2856 root     R     215m  22%   1  36% /tmp/bmcweb_ori           \n\u003e ```\n\u003e \n\u003e \u003e I\u0027m not really following how that would work.  If you already have epandLevel and expandType, what does expandStr give you?\n\u003e \n\u003e You don\u0027t want to re-generate the string again, so I propose to store the original value of those query parameters if we are going to use them again. But true, for expand, the value has to change. For select, we can probably directly use the original string. \n\nFor select, wouldn\u0027t we use the parsed result?  and store as vector\u003cstring\u003e?\n\n\u003e \n\u003e \u003e Keeping the existing \"parse the parameters once\" approach, then just make sure the delegate call can properly select sublevel handling instead of passing onto the existing handlers.\n\u003e How do we \"make sure the delegate call can properly select sublevel handling\"\n\nI don\u0027t think I understand the question;  It would select it the same way it does today?",
      "parentUuid": "96b46627_6ab3f25a",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6da4551c_ece06618",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000682
      },
      "writtenOn": "2022-05-10T17:02:42Z",
      "side": 1,
      "message": "\u003e For select, wouldn\u0027t we use the parsed result?  and store as vector\u003cstring\u003e?\n\nYes, that\u0027s what I went with in https://gerrit.openbmc-project.xyz/c/openbmc/bmcweb/+/53245/11. But you have concerns on regenerating the query string from the vector, right? Thus, to reduce memory usage and not to regenerate strings, I proposed \n\n```\n    std::string selectedPropertiesStr;\n    std::vector\u003cstd::string_view\u003e selectedProperties;\n```\n\nin the above comments.\n\n\u003e I don\u0027t think I understand the question;  It would select it the same way it does today?\n\nMy question is that inside MultiAsyncResp, how we can invoke efficient expand handlers. I\u0027m open to see other ideas other than what this commit proposes.",
      "parentUuid": "e37cf22b_455f598f",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7c39f6f0_a10884cc",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2022-05-10T18:20:35Z",
      "side": 1,
      "message": "\u003e \u003e For select, wouldn\u0027t we use the parsed result?  and store as vector\u003cstring\u003e?\n\u003e \n\u003e Yes, that\u0027s what I went with in https://gerrit.openbmc-project.xyz/c/openbmc/bmcweb/+/53245/11. But you have concerns on regenerating the query string from the vector, right? Thus, to reduce memory usage and not to regenerate strings, I proposed \n\nThe key here is that I want to avoid parsing user strings more than once, or generating a string from a struct, just to parse it back to a struct again.\n\n\u003e \n\u003e ```\n\u003e     std::string selectedPropertiesStr;\n\u003e     std::vector\u003cstd::string_view\u003e selectedProperties;\n\u003e ```\n\u003e \n\u003e in the above comments.\n\u003e \n\u003e \u003e I don\u0027t think I understand the question;  It would select it the same way it does today?\n\u003e \n\u003e My question is that inside MultiAsyncResp, how we can invoke efficient expand handlers. I\u0027m open to see other ideas other than what this commit proposes.\n\nUse the output of the log to determine if the efficient handler has already been done?",
      "parentUuid": "6da4551c_ece06618",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e72768cf_29405501",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000682
      },
      "writtenOn": "2022-05-10T19:49:12Z",
      "side": 1,
      "message": "Hmm, seems like I didn\u0027t make myself clear. Let me rephrase.\n\nFor any expand query, the current implementation does all queries in a single MultiAsyncResp, where the code sends a bunch of requests without Query parameters. This makes it impossible to invoke efficient expand handlers, since expand handlers will only be invoked when a query has $expand in its parameters. (Delegation only happens when the query contains query parameters)\n\nSo, to solve it, in this commit, I proposed to send a bunch of requests **WITH** Query parameters in MultiAsyncResp. This makes \"/redfish/v1/Chassis/chassis?expand\u003d.($levels\u003d2)\" be able to invoke efficient expand handlers that we developed for sensors, which existing implementation can\u0027t do.\n\nThe downside of it as you pointed out, we \"are parsing user strings more than once, or generating a string from a struct, just to parse it back to a struct again.\"\n\nIn my opinion, this downside is fine, as benchmarks show that \n\n1. memory doesn\u0027t increase significantly; part of the reason is that we are not copying Query anymore in MultiAsyncResp. No out-of-memory issues are found when 4 threads are querying expand\u003dlevels\u003d6 at the service root\n2. latency is significantly reduced because efficient handlers are invoked\n\n\u003e Use the output of the log to determine if the efficient handler has already been done?\n\nYes, I used this to verify this commit works during testing. But what I\u0027m asking is that in existing codes, how do we invoke efficient expand handlers if we send a bunch of requests without Query parameters\n\nHope this time I made myself clear.",
      "parentUuid": "7c39f6f0_a10884cc",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "3a93c8f4_54487a63",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000682
      },
      "writtenOn": "2022-05-12T17:16:54Z",
      "side": 1,
      "message": "Do you have any more comments?",
      "parentUuid": "e72768cf_29405501",
      "revId": "4aca086e69e214de467f5159a391669d7174e05d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    }
  ]
}