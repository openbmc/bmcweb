{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "d8091d5c_83e10d28",
        "filename": "redfish-core/include/utils/query_param.hpp",
        "patchSetId": 8
      },
      "lineNbr": 750,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2022-08-30T15:45:10Z",
      "side": 1,
      "message": "As written, for depth \u003d 2, isn\u0027t this going to get called multiple times in multiple objects?  That seems like it could run the BMC out of memory as the trees are being built, because the size is only estimated per MultiAsyncResp, which there could be multiple of, right?  Do we need to go back to having a single MultiAsyncResp object, prior to:\n\nhttps://github.com/openbmc/bmcweb/commit/72c3ae33bd127f8cd5887000a45adf13a56c7582",
      "range": {
        "startLine": 750,
        "startChar": 37,
        "endLine": 750,
        "endChar": 57
      },
      "revId": "ad2831ee6c2ab44c25629a90fedaa2249319e08d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7d718342_4c74de40",
        "filename": "redfish-core/include/utils/query_param.hpp",
        "patchSetId": 8
      },
      "lineNbr": 750,
      "author": {
        "id": 1000682
      },
      "writtenOn": "2022-08-30T18:40:41Z",
      "side": 1,
      "message": "That\u0027s a really good catch.\n\nThat commit enables efficient delegation which is an important feature that Google cares about. And even before that commit, we still create multiple AsyncResponse which could still blow up the memory (imagine a flat tree with depth 1 has 1000 URL to expand).\n\nThe only way to solve on top of my head is to limit the number of AsyncResponse this MultiAsyncResp creates via a static counter. This is not ideal but safe.\n\nThe ideal solution is to add a memory counter in side Crow::Response so that it doesn\u0027t allow new response to be created if a fair amount of memory has been used.\n\nI have updated the change. PTAL",
      "parentUuid": "d8091d5c_83e10d28",
      "range": {
        "startLine": 750,
        "startChar": 37,
        "endLine": 750,
        "endChar": 57
      },
      "revId": "ad2831ee6c2ab44c25629a90fedaa2249319e08d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0b3ba98f_808c3ecf",
        "filename": "redfish-core/include/utils/query_param.hpp",
        "patchSetId": 8
      },
      "lineNbr": 750,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2022-08-31T22:37:29Z",
      "side": 1,
      "message": "\u003e That\u0027s a really good catch.\n\u003e \n\u003e That commit enables efficient delegation which is an important feature that Google cares about.\n\nI think we can get both behaviors.  I never said nobody cared about the feature, I\u0027m just saying it\u0027s pointing out that maybe we need one \"main\" object instead of many small ones.\n\n\u003e And even before that commit, we still create multiple AsyncResponse which could still blow up the memory (imagine a flat tree with depth 1 has 1000 URL to expand).\n\nI\u0027m a lot less concerned about that.  Each individual AsyncResp is going to be reasonably small, and each handler has some expectation that it enforce some amount of restraint in objects.  Also, in your example, remember, that only one AsyncResponse object is going to be filled in at a time, so even if there\u0027s 1000 AsyncResp objects, the moment each one \"fills\" with data, it will call end(), and won\u0027t blow up memory for more than one object at a time.\n\n\u003e \n\u003e The only way to solve on top of my head is to limit the number of AsyncResponse this MultiAsyncResp creates via a static counter. This is not ideal but safe.\n\nI don\u0027t think this is a real concern.  AsyncResponse itself is a relatively small object, with just a Response member, and that response member by default construction is also small.  With that said, I wouldn\u0027t be against a static counter if we could prove that it was needed.  We do this same pattern other places for things like http connection limits.\n\n\u003e \n\u003e The ideal solution is to add a memory counter in side Crow::Response so that it doesn\u0027t allow new response to be created if a fair amount of memory has been used.\n\nI\u0027m not sure I understand this idea.  Crow::Response is supposed to be a response object for Http requests, why would it itself be measuring memory usage?  If a Response object is created inside HttpConnection, that shouldn\u0027t be possible to fail (because connections are already limited in other ways), so I don\u0027t think this works as stated, but maybe I\u0027m misunderstanding.\n\n\u003e \n\u003e I have updated the change. PTAL",
      "parentUuid": "7d718342_4c74de40",
      "range": {
        "startLine": 750,
        "startChar": 37,
        "endLine": 750,
        "endChar": 57
      },
      "revId": "ad2831ee6c2ab44c25629a90fedaa2249319e08d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "95b290c5_d7212413",
        "filename": "redfish-core/include/utils/query_param.hpp",
        "patchSetId": 8
      },
      "lineNbr": 750,
      "author": {
        "id": 1000682
      },
      "writtenOn": "2022-09-01T18:57:08Z",
      "side": 1,
      "message": "\u003e I\u0027m a lot less concerned about that.  Each individual AsyncResp is going to be reasonably small, and each handler has some expectation that it enforce some amount of restraint in objects.  Also, in your example, remember, that only one AsyncResponse object is going to be filled in at a time, so even if there\u0027s 1000 AsyncResp objects, the moment each one \"fills\" with data, it will call end(), and won\u0027t blow up memory for more than one object at a time.\n\nI have replied to this in Discord. There can be cases where multiple AsyncResponse are pending and each of them has a fair amount of data. \n\nGot a better idea here: execute sub expand query one by one. In this implementation, we will do deep first search for a sub node (e.g., ComputerSystem), then query the next sub node.\n\nI updated the commit message as well.\n\nPTAL.",
      "parentUuid": "0b3ba98f_808c3ecf",
      "range": {
        "startLine": 750,
        "startChar": 37,
        "endLine": 750,
        "endChar": 57
      },
      "revId": "ad2831ee6c2ab44c25629a90fedaa2249319e08d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e7386d6d_7ad58097",
        "filename": "redfish-core/include/utils/query_param.hpp",
        "patchSetId": 8
      },
      "lineNbr": 750,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2023-03-15T17:18:44Z",
      "side": 1,
      "message": "This doesn\u0027t look like it was done, which is why I haven\u0027t looked at this patch in a bit.  I\u0027m not quite understanding what you\u0027re suggesting, can you come up with a patch (even if it\u0027s WIP quality) that talks through what you\u0027re thinking?\n\n\n\u003e  execute sub expand query one by one.\n\nWon\u0027t this be really slow?  There were expand implementations that did this previously, and the performance was way worse (like 2-8X worse).",
      "parentUuid": "95b290c5_d7212413",
      "range": {
        "startLine": 750,
        "startChar": 37,
        "endLine": 750,
        "endChar": 57
      },
      "revId": "ad2831ee6c2ab44c25629a90fedaa2249319e08d",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    }
  ]
}